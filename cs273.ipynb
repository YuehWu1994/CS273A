{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cs273.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "PfT5B51qrpoB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#  CS 273A, Machine Learning, Final Project\n"
      ]
    },
    {
      "metadata": {
        "id": "BNQWyO6DsBOO",
        "colab_type": "code",
        "outputId": "4e17e666-299b-4ac8-f2f5-fe4e2b41af10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/brian2213/CS273A"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CS273A'...\n",
            "remote: Enumerating objects: 120, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/120)   \u001b[K\rremote: Counting objects:   1% (2/120)   \u001b[K\rremote: Counting objects:   2% (3/120)   \u001b[K\rremote: Counting objects:   3% (4/120)   \u001b[K\rremote: Counting objects:   4% (5/120)   \u001b[K\rremote: Counting objects:   5% (6/120)   \u001b[K\rremote: Counting objects:   6% (8/120)   \u001b[K\rremote: Counting objects:   7% (9/120)   \u001b[K\rremote: Counting objects:   8% (10/120)   \u001b[K\rremote: Counting objects:   9% (11/120)   \u001b[K\rremote: Counting objects:  10% (12/120)   \u001b[K\rremote: Counting objects:  11% (14/120)   \u001b[K\rremote: Counting objects:  12% (15/120)   \u001b[K\rremote: Counting objects:  13% (16/120)   \u001b[K\rremote: Counting objects:  14% (17/120)   \u001b[K\rremote: Counting objects:  15% (18/120)   \u001b[K\rremote: Counting objects:  16% (20/120)   \u001b[K\rremote: Counting objects:  17% (21/120)   \u001b[K\rremote: Counting objects:  18% (22/120)   \u001b[K\rremote: Counting objects:  19% (23/120)   \u001b[K\rremote: Counting objects:  20% (24/120)   \u001b[K\rremote: Counting objects:  21% (26/120)   \u001b[K\rremote: Counting objects:  22% (27/120)   \u001b[K\rremote: Counting objects:  23% (28/120)   \u001b[K\rremote: Counting objects:  24% (29/120)   \u001b[K\rremote: Counting objects:  25% (30/120)   \u001b[K\rremote: Counting objects:  26% (32/120)   \u001b[K\rremote: Counting objects:  27% (33/120)   \u001b[K\rremote: Counting objects:  28% (34/120)   \u001b[K\rremote: Counting objects:  29% (35/120)   \u001b[K\rremote: Counting objects:  30% (36/120)   \u001b[K\rremote: Counting objects:  31% (38/120)   \u001b[K\rremote: Counting objects:  32% (39/120)   \u001b[K\rremote: Counting objects:  33% (40/120)   \u001b[K\rremote: Counting objects:  34% (41/120)   \u001b[K\rremote: Counting objects:  35% (42/120)   \u001b[K\rremote: Counting objects:  36% (44/120)   \u001b[K\rremote: Counting objects:  37% (45/120)   \u001b[K\rremote: Counting objects:  38% (46/120)   \u001b[K\rremote: Counting objects:  39% (47/120)   \u001b[K\rremote: Counting objects:  40% (48/120)   \u001b[K\rremote: Counting objects:  41% (50/120)   \u001b[K\rremote: Counting objects:  42% (51/120)   \u001b[K\rremote: Counting objects:  43% (52/120)   \u001b[K\rremote: Counting objects:  44% (53/120)   \u001b[K\rremote: Counting objects:  45% (54/120)   \u001b[K\rremote: Counting objects:  46% (56/120)   \u001b[K\rremote: Counting objects:  47% (57/120)   \u001b[K\rremote: Counting objects:  48% (58/120)   \u001b[K\rremote: Counting objects:  49% (59/120)   \u001b[K\rremote: Counting objects:  50% (60/120)   \u001b[K\rremote: Counting objects:  51% (62/120)   \u001b[K\rremote: Counting objects:  52% (63/120)   \u001b[K\rremote: Counting objects:  53% (64/120)   \u001b[K\rremote: Counting objects:  54% (65/120)   \u001b[K\rremote: Counting objects:  55% (66/120)   \u001b[K\rremote: Counting objects:  56% (68/120)   \u001b[K\rremote: Counting objects:  57% (69/120)   \u001b[K\rremote: Counting objects:  58% (70/120)   \u001b[K\rremote: Counting objects:  59% (71/120)   \u001b[K\rremote: Counting objects:  60% (72/120)   \u001b[K\rremote: Counting objects:  61% (74/120)   \u001b[K\rremote: Counting objects:  62% (75/120)   \u001b[K\rremote: Counting objects:  63% (76/120)   \u001b[K\rremote: Counting objects:  64% (77/120)   \rremote: Counting objects:  65% (78/120)   \u001b[K\rremote: Counting objects:  66% (80/120)   \u001b[K\rremote: Counting objects:  67% (81/120)   \u001b[K\rremote: Counting objects:  68% (82/120)   \u001b[K\rremote: Counting objects:  69% (83/120)   \u001b[K\rremote: Counting objects:  70% (84/120)   \u001b[K\rremote: Counting objects:  71% (86/120)   \u001b[K\rremote: Counting objects:  72% (87/120)   \u001b[K\rremote: Counting objects:  73% (88/120)   \u001b[K\rremote: Counting objects:  74% (89/120)   \u001b[K\rremote: Counting objects:  75% (90/120)   \u001b[K\rremote: Counting objects:  76% (92/120)   \u001b[K\rremote: Counting objects:  77% (93/120)   \u001b[K\rremote: Counting objects:  78% (94/120)   \u001b[K\rremote: Counting objects:  79% (95/120)   \u001b[K\rremote: Counting objects:  80% (96/120)   \u001b[K\rremote: Counting objects:  81% (98/120)   \u001b[K\rremote: Counting objects:  82% (99/120)   \u001b[K\rremote: Counting objects:  83% (100/120)   \u001b[K\rremote: Counting objects:  84% (101/120)   \u001b[K\rremote: Counting objects:  85% (102/120)   \u001b[K\rremote: Counting objects:  86% (104/120)   \u001b[K\rremote: Counting objects:  87% (105/120)   \u001b[K\rremote: Counting objects:  88% (106/120)   \u001b[K\rremote: Counting objects:  89% (107/120)   \u001b[K\rremote: Counting objects:  90% (108/120)   \u001b[K\rremote: Counting objects:  91% (110/120)   \u001b[K\rremote: Counting objects:  92% (111/120)   \u001b[K\rremote: Counting objects:  93% (112/120)   \u001b[K\rremote: Counting objects:  94% (113/120)   \u001b[K\rremote: Counting objects:  95% (114/120)   \u001b[K\rremote: Counting objects:  96% (116/120)   \u001b[K\rremote: Counting objects:  97% (117/120)   \u001b[K\rremote: Counting objects:  98% (118/120)   \u001b[K\rremote: Counting objects:  99% (119/120)   \u001b[K\rremote: Counting objects: 100% (120/120)   \u001b[K\rremote: Counting objects: 100% (120/120), done.\u001b[K\n",
            "remote: Compressing objects: 100% (73/73), done.\u001b[K\n",
            "remote: Total 120 (delta 64), reused 98 (delta 42), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (120/120), 306.63 KiB | 5.79 MiB/s, done.\n",
            "Resolving deltas: 100% (64/64), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3H3NJtxe3BSz",
        "colab_type": "code",
        "outputId": "4f02fced-b0c1-4b9f-c255-81116d409594",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "%cd CS273A/"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/CS273A\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "j_KaE95V3GkH",
        "colab_type": "code",
        "outputId": "52343f55-7aa4-405b-d128-a41b64b4990f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2553
        }
      },
      "cell_type": "code",
      "source": [
        "!sh getRequirement.sh"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading and extracting CoLA...\n",
            "\tCompleted!\n",
            "Downloading and extracting SST...\n",
            "\tCompleted!\n",
            "Processing MRPC...\n",
            "\tCompleted!\n",
            "Downloading and extracting QQP...\n",
            "\tCompleted!\n",
            "Downloading and extracting STS...\n",
            "\tCompleted!\n",
            "Downloading and extracting MNLI...\n",
            "\tCompleted!\n",
            "Downloading and extracting SNLI...\n",
            "\tCompleted!\n",
            "Downloading and extracting QNLI...\n",
            "\tCompleted!\n",
            "Downloading and extracting RTE...\n",
            "\tCompleted!\n",
            "Downloading and extracting WNLI...\n",
            "\tCompleted!\n",
            "Downloading and extracting diagnostic...\n",
            "\tCompleted!\n",
            "--2018-12-03 23:39:32--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2018-12-03 23:39:32--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  41.9MB/s    in 23s     \n",
            "\n",
            "2018-12-03 23:39:56 (35.9 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n",
            "Requirement already satisfied: ipdb in /usr/local/lib/python3.6/dist-packages (0.11)\n",
            "Requirement already satisfied: ipython>=5.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipdb) (5.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from ipdb) (40.6.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0; python_version >= \"3.3\"->ipdb) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0; python_version >= \"3.3\"->ipdb) (1.0.15)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0; python_version >= \"3.3\"->ipdb) (4.3.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0; python_version >= \"3.3\"->ipdb) (4.3.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0; python_version >= \"3.3\"->ipdb) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0; python_version >= \"3.3\"->ipdb) (4.6.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0; python_version >= \"3.3\"->ipdb) (2.1.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.0.0; python_version >= \"3.3\"->ipdb) (0.1.7)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.0.0; python_version >= \"3.3\"->ipdb) (1.11.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython>=5.0.0; python_version >= \"3.3\"->ipdb) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.0.0; python_version >= \"3.3\"->ipdb) (0.6.0)\n",
            "Collecting torch==0.4\n",
            "  Using cached https://files.pythonhosted.org/packages/69/43/380514bd9663f1bf708abeb359b8b48d3fabb1c8e95bb3427a980a064c57/torch-0.4.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "tcmalloc: large alloc 1073750016 bytes == 0x5ae84000 @  0x7f368f94d2a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
            "\u001b[31mpytorch-pretrained-bert 0.1.2 has requirement torch>=0.4.1, but you'll have torch 0.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mallennlp 0.4.3 has requirement torch==0.3.1, but you'll have torch 0.4.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 0.3.1\n",
            "    Uninstalling torch-0.3.1:\n",
            "      Successfully uninstalled torch-0.3.1\n",
            "Successfully installed torch-0.4.0\n",
            "Requirement already satisfied: allennlp==0.4.3 in /usr/local/lib/python3.6/dist-packages (0.4.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from allennlp==0.4.3) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from allennlp==0.4.3) (0.19.2)\n",
            "Requirement already satisfied: awscli>=1.11.91 in /usr/local/lib/python3.6/dist-packages (from allennlp==0.4.3) (1.16.67)\n",
            "Requirement already satisfied: tensorboardX==1.0 in /usr/local/lib/python3.6/dist-packages (from allennlp==0.4.3) (1.0)\n",
            "Requirement already satisfied: gevent==1.2.2 in /usr/local/lib/python3.6/dist-packages (from allennlp==0.4.3) (1.2.2)\n",
            "Requirement already satisfied: cffi==1.11.2 in /usr/local/lib/python3.6/dist-packages (from allennlp==0.4.3) (1.11.2)\n",
            "Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.6/dist-packages (from allennlp==0.4.3) (4.28.1)\n",
            "Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.6/dist-packages (from allennlp==0.4.3) (2.18.4)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.6/dist-packages (from allennlp==0.4.3) (0.5.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from allennlp==0.4.3) (2.8.0)\n",
            "Requirement already satisfied: spacy<2.1,>=2.0 in /usr/local/lib/python3.6/dist-packages (from allennlp==0.4.3) (2.0.17)\n",
            "Requirement already satisfied: flaky in /usr/local/lib/python3.6/dist-packages (from allennlp==0.4.3) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from allennlp==0.4.3) (1.14.6)\n",
            "Requirement already satisfied: flask-cors==3.0.3 in /usr/local/lib/python3.6/dist-packages (from allennlp==0.4.3) (3.0.3)\n",
            "Requirement already satisfied: psycopg2 in /usr/local/lib/python3.6/dist-packages (from allennlp==0.4.3) (2.7.6.1)\n",
            "Requirement already satisfied: pytz==2017.3 in /usr/local/lib/python3.6/dist-packages (from allennlp==0.4.3) (2017.3)\n",
            "Collecting torch==0.3.1 (from allennlp==0.4.3)\n",
            "  Using cached https://files.pythonhosted.org/packages/5b/a5/e8b50b55b1abac9f1e3346c4242f1e42a82d368a8442cbd50c532922f6c4/torch-0.3.1-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from allennlp==0.4.3) (3.6.6)\n",
            "Requirement already satisfied: pyhocon==0.3.35 in /usr/local/lib/python3.6/dist-packages (from allennlp==0.4.3) (0.3.35)\n",
            "Requirement already satisfied: overrides in /usr/local/lib/python3.6/dist-packages (from allennlp==0.4.3) (1.9)\n",
            "Requirement already satisfied: flask==0.12.1 in /usr/local/lib/python3.6/dist-packages (from allennlp==0.4.3) (0.12.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from allennlp==0.4.3) (3.2.5)\n",
            "Requirement already satisfied: responses>=0.7 in /usr/local/lib/python3.6/dist-packages (from allennlp==0.4.3) (0.10.4)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from allennlp==0.4.3) (3.10.1)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (from allennlp==0.4.3) (1.0.23)\n",
            "Requirement already satisfied: rsa<=3.5.0,>=3.1.2 in /usr/local/lib/python3.6/dist-packages (from awscli>=1.11.91->allennlp==0.4.3) (3.4.2)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from awscli>=1.11.91->allennlp==0.4.3) (0.14)\n",
            "Requirement already satisfied: botocore==1.12.57 in /usr/local/lib/python3.6/dist-packages (from awscli>=1.11.91->allennlp==0.4.3) (1.12.57)\n",
            "Requirement already satisfied: colorama<=0.3.9,>=0.2.5 in /usr/local/lib/python3.6/dist-packages (from awscli>=1.11.91->allennlp==0.4.3) (0.3.9)\n",
            "Requirement already satisfied: s3transfer<0.2.0,>=0.1.12 in /usr/local/lib/python3.6/dist-packages (from awscli>=1.11.91->allennlp==0.4.3) (0.1.13)\n",
            "Requirement already satisfied: PyYAML<=3.13,>=3.10 in /usr/local/lib/python3.6/dist-packages (from awscli>=1.11.91->allennlp==0.4.3) (3.13)\n",
            "Requirement already satisfied: protobuf>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorboardX==1.0->allennlp==0.4.3) (3.6.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX==1.0->allennlp==0.4.3) (1.11.0)\n",
            "Requirement already satisfied: greenlet>=0.4.10 in /usr/local/lib/python3.6/dist-packages (from gevent==1.2.2->allennlp==0.4.3) (0.4.15)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi==1.11.2->allennlp==0.4.3) (2.19)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp==0.4.3) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp==0.4.3) (2018.10.15)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp==0.4.3) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp==0.4.3) (1.22)\n",
            "Requirement already satisfied: msgpack-numpy<0.4.4 in /usr/local/lib/python3.6/dist-packages (from spacy<2.1,>=2.0->allennlp==0.4.3) (0.4.3.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.1,>=2.0->allennlp==0.4.3) (1.0.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.1,>=2.0->allennlp==0.4.3) (2.0.2)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.1,>=2.0->allennlp==0.4.3) (2.0.1)\n",
            "Requirement already satisfied: thinc<6.13.0,>=6.12.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.1,>=2.0->allennlp==0.4.3) (6.12.0)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.1,>=2.0->allennlp==0.4.3) (0.9.6)\n",
            "Requirement already satisfied: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy<2.1,>=2.0->allennlp==0.4.3) (1.35)\n",
            "Requirement already satisfied: dill<0.3,>=0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.1,>=2.0->allennlp==0.4.3) (0.2.8.2)\n",
            "Requirement already satisfied: regex<2017.12.1,>=2017.4.5 in /usr/local/lib/python3.6/dist-packages (from spacy<2.1,>=2.0->allennlp==0.4.3) (2017.11.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from pyhocon==0.3.35->allennlp==0.4.3) (2.3.0)\n",
            "Requirement already satisfied: Werkzeug>=0.7 in /usr/local/lib/python3.6/dist-packages (from flask==0.12.1->allennlp==0.4.3) (0.14.1)\n",
            "Requirement already satisfied: Jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from flask==0.12.1->allennlp==0.4.3) (2.10)\n",
            "Requirement already satisfied: click>=2.0 in /usr/local/lib/python3.6/dist-packages (from flask==0.12.1->allennlp==0.4.3) (7.0)\n",
            "Requirement already satisfied: itsdangerous>=0.21 in /usr/local/lib/python3.6/dist-packages (from flask==0.12.1->allennlp==0.4.3) (1.1.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==0.4.3) (4.3.0)\n",
            "Requirement already satisfied: pluggy>=0.7 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==0.4.3) (0.8.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==0.4.3) (1.2.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==0.4.3) (40.6.2)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==0.4.3) (1.7.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==0.4.3) (18.2.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<=3.5.0,>=3.1.2->awscli>=1.11.91->allennlp==0.4.3) (0.4.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore==1.12.57->awscli>=1.11.91->allennlp==0.4.3) (2.5.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from botocore==1.12.57->awscli>=1.11.91->allennlp==0.4.3) (0.9.3)\n",
            "Requirement already satisfied: msgpack>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from msgpack-numpy<0.4.4->spacy<2.1,>=2.0->allennlp==0.4.3) (0.5.6)\n",
            "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.0->spacy<2.1,>=2.0->allennlp==0.4.3) (0.9.0.1)\n",
            "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.0->spacy<2.1,>=2.0->allennlp==0.4.3) (1.10.11)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.4->flask==0.12.1->allennlp==0.4.3) (1.1.0)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.0->spacy<2.1,>=2.0->allennlp==0.4.3) (0.9.0)\n",
            "\u001b[31mpytorch-pretrained-bert 0.1.2 has requirement torch>=0.4.1, but you'll have torch 0.3.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 0.4.0\n",
            "    Uninstalling torch-0.4.0:\n",
            "      Successfully uninstalled torch-0.4.0\n",
            "Successfully installed torch-0.3.1\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.6/dist-packages (1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.14.6)\n",
            "Requirement already satisfied: protobuf>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.6.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=0.3.2->tensorboardX) (40.6.2)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QPoU76MB3ImN",
        "colab_type": "code",
        "outputId": "3db868ef-c380-40e4-d92c-dc50ad20f65d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "%cd src/"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/CS273A/src\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PzvpfpSWLqm_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6236
        },
        "outputId": "1e8b26cb-f54a-408c-8460-887c86700829"
      },
      "cell_type": "code",
      "source": [
        "!sh run_stuff_GPU.sh"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[TerminalIPythonApp] WARNING | GUI event loop or pylab initialization failed\n",
            "\u001b]0;IPython: CS273A/src\u0007\u001b[0;31m\u001b[0m\n",
            "\u001b[0;31mUnknownBackend\u001b[0mTraceback (most recent call last)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36menable_matplotlib\u001b[0;34m(self, gui)\u001b[0m\n",
            "\u001b[1;32m   2953\u001b[0m         \u001b[0;31m# Now we must activate the gui pylab wants to use, and fix %run to take\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m   2954\u001b[0m         \u001b[0;31m# plot updates into account\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m-> 2955\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_gui\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[1;32m   2956\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagics_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ExecutionMagics'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_runner\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m   2957\u001b[0m             \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmpl_runner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafe_execfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/terminal/interactiveshell.py\u001b[0m in \u001b[0;36menable_gui\u001b[0;34m(self, gui)\u001b[0m\n",
            "\u001b[1;32m    512\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgui\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    513\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_eventloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inputhook\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 514\u001b[0;31m                 \u001b[0mget_inputhook_name_and_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[1;32m    515\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    516\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_eventloop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inputhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/terminal/pt_inputhooks/__init__.py\u001b[0m in \u001b[0;36mget_inputhook_name_and_func\u001b[0;34m(gui)\u001b[0m\n",
            "\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     37\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgui\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mUnknownBackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     40\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgui\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maliases\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;31mUnknownBackend\u001b[0m: No event loop integration for 'inline'. Supported event loops are: qt, qt4, qt5, gtk, gtk2, gtk3, tk, wx, pyglet, glut, osx\n",
            "/usr/local/lib/python3.6/dist-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
            "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n",
            "12/03 11:42:22 PM: Namespace(batch_size=64, bpp_base=10, bpp_method='percent_tr', classifier='mlp', classifier_dropout=0.0, classifier_hid_dim=512, cove=0, cuda=-1, d_hid=512, d_word=300, deep_elmo=1, dropout=0.2, dropout_embs=0.2, elmo=1, elmo_no_glove=1, eval_tasks='none', exp_dir='EXP_DIR', glove=0, load_epoch=-1, load_model=0, load_preproc=1, load_tasks=1, log_file='log.log', lr=0.1, lr_decay_factor=0.5, max_grad_norm=5.0, max_seq_len=40, max_vals=100, max_word_v_size=30000, min_lr=1e-05, n_epochs=10, n_layers_enc=1, n_layers_highway=0, no_tqdm=0, optimizer='sgd', pair_enc='simple', patience=5, preproc_file='preproc.pkl', random_seed=19, run_dir='RUN_DIR', scaling_method='none', scheduler_threshold=0.0, shared_optimizer=1, should_train=1, task_ordering='random', task_patience=0, train_tasks='cola', train_words=0, trainer_type='sampling', val_interval=10, weight_decay=0.0, weighting_method='uniform', word_embs_file='../glove/glove.6B/glove.6B.300d.txt')\n",
            "12/03 11:42:22 PM: Using random seed 19\n",
            "12/03 11:42:22 PM: Loading tasks...\n",
            "12/03 11:42:22 PM: \tLoaded existing task cola\n",
            "12/03 11:42:22 PM: \tFinished loading tasks: cola.\n",
            "12/03 11:42:22 PM: \tProcessing tasks from scratch\n",
            "12/03 11:42:22 PM: \tFinished counting words\n",
            "12/03 11:42:22 PM: \tFinished building vocab. Using 6395 words\n",
            "12/03 11:42:28 PM: \tFinished loading embeddings\n",
            "12/03 11:42:29 PM: Your label namespace was 'idxs'. We recommend you use a namespace ending with 'labels' or 'tags', so we don't add UNK and PAD tokens by default to your vocabulary.  See documentation for `non_padded_namespaces` parameter in Vocabulary.\n",
            "12/03 11:42:30 PM: \tFinished indexing tasks\n",
            "12/03 11:42:31 PM: \tSaved data to EXP_DIR/preproc.pkl\n",
            "12/03 11:42:31 PM: \t  Training on cola\n",
            "12/03 11:42:31 PM: \t  Evaluating on \n",
            "12/03 11:42:31 PM: \tFinished loading tasks in 9.259s\n",
            "12/03 11:42:31 PM: Building model...\n",
            "12/03 11:42:31 PM: \tLearning embeddings from scratch!\n",
            "12/03 11:42:31 PM: \tUsing ELMo embeddings!\n",
            "12/03 11:42:31 PM: \tUsing deep ELMo embeddings!\n",
            "12/03 11:42:31 PM: \tNOT using GLoVe embeddings!\n",
            "12/03 11:42:31 PM: Initializing ELMo\n",
            "12/03 11:42:54 PM: batch_first = True\n",
            "12/03 11:42:54 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
            "12/03 11:42:54 PM: CURRENTLY DEFINED PARAMETERS: \n",
            "12/03 11:42:54 PM: input_size = 1024\n",
            "12/03 11:42:54 PM: hidden_size = 512\n",
            "12/03 11:42:54 PM: num_layers = 1\n",
            "12/03 11:42:54 PM: bidirectional = True\n",
            "12/03 11:42:54 PM: batch_first = True\n",
            "12/03 11:42:54 PM: Initializing parameters\n",
            "12/03 11:42:54 PM: Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder._char_embedding_weights\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder._highways._layers.0.bias\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder._highways._layers.0.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder._highways._layers.1.bias\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder._highways._layers.1.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder._projection.bias\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder._projection.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder.char_conv_0.bias\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder.char_conv_0.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder.char_conv_1.bias\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder.char_conv_1.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder.char_conv_2.bias\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder.char_conv_2.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder.char_conv_3.bias\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder.char_conv_3.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder.char_conv_4.bias\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder.char_conv_4.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder.char_conv_5.bias\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder.char_conv_5.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder.char_conv_6.bias\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder.char_conv_6.weight\n",
            "12/03 11:42:54 PM:    _elmo.scalar_mix_0.gamma\n",
            "12/03 11:42:54 PM:    _elmo.scalar_mix_0.scalar_parameters.0\n",
            "12/03 11:42:54 PM:    _elmo.scalar_mix_0.scalar_parameters.1\n",
            "12/03 11:42:54 PM:    _elmo.scalar_mix_0.scalar_parameters.2\n",
            "12/03 11:42:54 PM:    _elmo.scalar_mix_1.gamma\n",
            "12/03 11:42:54 PM:    _elmo.scalar_mix_1.scalar_parameters.0\n",
            "12/03 11:42:54 PM:    _elmo.scalar_mix_1.scalar_parameters.1\n",
            "12/03 11:42:54 PM:    _elmo.scalar_mix_1.scalar_parameters.2\n",
            "12/03 11:42:54 PM:    _phrase_layer._module.bias_hh_l0\n",
            "12/03 11:42:54 PM:    _phrase_layer._module.bias_hh_l0_reverse\n",
            "12/03 11:42:54 PM:    _phrase_layer._module.bias_ih_l0\n",
            "12/03 11:42:54 PM:    _phrase_layer._module.bias_ih_l0_reverse\n",
            "12/03 11:42:54 PM:    _phrase_layer._module.weight_hh_l0\n",
            "12/03 11:42:54 PM:    _phrase_layer._module.weight_hh_l0_reverse\n",
            "12/03 11:42:54 PM:    _phrase_layer._module.weight_ih_l0\n",
            "12/03 11:42:54 PM:    _phrase_layer._module.weight_ih_l0_reverse\n",
            "12/03 11:42:54 PM: Initializing parameters\n",
            "12/03 11:42:54 PM: Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder._char_embedding_weights\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder._highways._layers.0.bias\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder._highways._layers.0.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder._highways._layers.1.bias\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder._highways._layers.1.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder._projection.bias\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder._projection.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder.char_conv_0.bias\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder.char_conv_0.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder.char_conv_1.bias\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder.char_conv_1.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder.char_conv_2.bias\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder.char_conv_2.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder.char_conv_3.bias\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder.char_conv_3.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder.char_conv_4.bias\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder.char_conv_4.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder.char_conv_5.bias\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder.char_conv_5.weight\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder.char_conv_6.bias\n",
            "12/03 11:42:54 PM:    _elmo._elmo_lstm._token_embedder.char_conv_6.weight\n",
            "12/03 11:42:54 PM:    _elmo.scalar_mix_0.gamma\n",
            "12/03 11:42:54 PM:    _elmo.scalar_mix_0.scalar_parameters.0\n",
            "12/03 11:42:54 PM:    _elmo.scalar_mix_0.scalar_parameters.1\n",
            "12/03 11:42:54 PM:    _elmo.scalar_mix_0.scalar_parameters.2\n",
            "12/03 11:42:54 PM:    _elmo.scalar_mix_1.gamma\n",
            "12/03 11:42:54 PM:    _elmo.scalar_mix_1.scalar_parameters.0\n",
            "12/03 11:42:54 PM:    _elmo.scalar_mix_1.scalar_parameters.1\n",
            "12/03 11:42:54 PM:    _elmo.scalar_mix_1.scalar_parameters.2\n",
            "12/03 11:42:54 PM:    _phrase_layer._module.bias_hh_l0\n",
            "12/03 11:42:54 PM:    _phrase_layer._module.bias_hh_l0_reverse\n",
            "12/03 11:42:54 PM:    _phrase_layer._module.bias_ih_l0\n",
            "12/03 11:42:54 PM:    _phrase_layer._module.bias_ih_l0_reverse\n",
            "12/03 11:42:54 PM:    _phrase_layer._module.weight_hh_l0\n",
            "12/03 11:42:54 PM:    _phrase_layer._module.weight_hh_l0_reverse\n",
            "12/03 11:42:54 PM:    _phrase_layer._module.weight_ih_l0\n",
            "12/03 11:42:54 PM:    _phrase_layer._module.weight_ih_l0_reverse\n",
            "12/03 11:42:54 PM: \tFinished building model in 22.890s\n",
            "12/03 11:42:54 PM: patience = 5\n",
            "12/03 11:42:54 PM: num_epochs = 10\n",
            "12/03 11:42:54 PM: max_vals = 50\n",
            "12/03 11:42:54 PM: cuda_device = -1\n",
            "12/03 11:42:54 PM: grad_norm = 5.0\n",
            "12/03 11:42:54 PM: grad_clipping = None\n",
            "12/03 11:42:54 PM: lr_decay = 0.99\n",
            "12/03 11:42:54 PM: min_lr = 1e-05\n",
            "12/03 11:42:54 PM: no_tqdm = 0\n",
            "12/03 11:42:54 PM: Sampling tasks uniformly\n",
            "12/03 11:42:54 PM: type = sgd\n",
            "12/03 11:42:54 PM: parameter_groups = None\n",
            "12/03 11:42:54 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
            "12/03 11:42:54 PM: CURRENTLY DEFINED PARAMETERS: \n",
            "12/03 11:42:54 PM: lr = 0.1\n",
            "12/03 11:42:54 PM: weight_decay = 1e-05\n",
            "12/03 11:42:54 PM: type = reduce_on_plateau\n",
            "12/03 11:42:54 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
            "12/03 11:42:54 PM: CURRENTLY DEFINED PARAMETERS: \n",
            "12/03 11:42:54 PM: mode = max\n",
            "12/03 11:42:54 PM: factor = 0.5\n",
            "12/03 11:42:54 PM: patience = 0\n",
            "12/03 11:42:54 PM: threshold = 0.0\n",
            "12/03 11:42:54 PM: threshold_mode = abs\n",
            "12/03 11:42:54 PM: verbose = True\n",
            "12/03 11:42:54 PM: type = sgd\n",
            "12/03 11:42:54 PM: parameter_groups = None\n",
            "12/03 11:42:54 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
            "12/03 11:42:54 PM: CURRENTLY DEFINED PARAMETERS: \n",
            "12/03 11:42:54 PM: lr = 0.1\n",
            "12/03 11:42:54 PM: weight_decay = 1e-05\n",
            "12/03 11:42:54 PM: type = reduce_on_plateau\n",
            "12/03 11:42:54 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
            "12/03 11:42:54 PM: CURRENTLY DEFINED PARAMETERS: \n",
            "12/03 11:42:54 PM: mode = max\n",
            "12/03 11:42:54 PM: factor = 0.5\n",
            "12/03 11:42:54 PM: patience = 0\n",
            "12/03 11:42:54 PM: threshold = 0.0\n",
            "12/03 11:42:54 PM: threshold_mode = abs\n",
            "12/03 11:42:54 PM: verbose = True\n",
            "12/03 11:42:54 PM: Beginning training.\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
            "12/03 11:44:33 PM: Update 10: task cola, batch 10 (10): accuracy: 0.0093, acc: 0.6562, cola_loss: 0.8508 ||\n",
            "12/03 11:44:33 PM: ***** Pass 10 / Epoch 1 *****\n",
            "12/03 11:44:33 PM: cola: trained on 10 batches, 0.075 epochs\n",
            "12/03 11:44:33 PM: Validating...\n",
            "12/03 11:44:48 PM: Batch 2/17: accuracy: 0.0000, acc: 0.7734, cola_loss: 0.5739 ||\n",
            "12/03 11:45:04 PM: Batch 4/17: accuracy: 0.0000, acc: 0.7305, cola_loss: 0.5991 ||\n",
            "12/03 11:45:21 PM: Batch 6/17: accuracy: 0.0000, acc: 0.7214, cola_loss: 0.6019 ||\n",
            "12/03 11:45:36 PM: Batch 8/17: accuracy: 0.0000, acc: 0.7129, cola_loss: 0.6080 ||\n",
            "12/03 11:45:50 PM: Batch 10/17: accuracy: 0.0000, acc: 0.7141, cola_loss: 0.6066 ||\n",
            "12/03 11:46:06 PM: Batch 12/17: accuracy: 0.0000, acc: 0.7057, cola_loss: 0.6120 ||\n",
            "12/03 11:46:22 PM: Batch 14/17: accuracy: 0.0000, acc: 0.6942, cola_loss: 0.6181 ||\n",
            "12/03 11:46:35 PM: Batch 16/17: accuracy: 0.0000, acc: 0.6895, cola_loss: 0.6210 ||\n",
            "12/03 11:46:38 PM: Best model found for cola.\n",
            "12/03 11:46:38 PM: Best model found for micro.\n",
            "12/03 11:46:38 PM: Best model found for macro.\n",
            "12/03 11:46:38 PM: Statistic: cola_loss\n",
            "12/03 11:46:38 PM: \ttraining: 0.850830\n",
            "12/03 11:46:38 PM: \tvalidation: 0.616861\n",
            "12/03 11:46:38 PM: Statistic: macro_accuracy\n",
            "12/03 11:46:38 PM: \tvalidation: 0.000000\n",
            "12/03 11:46:38 PM: Statistic: micro_accuracy\n",
            "12/03 11:46:38 PM: \tvalidation: 0.000000\n",
            "12/03 11:46:38 PM: Statistic: cola_accuracy\n",
            "12/03 11:46:38 PM: \ttraining: 0.009288\n",
            "12/03 11:46:38 PM: \tvalidation: 0.000000\n",
            "12/03 11:46:38 PM: Statistic: cola_acc\n",
            "12/03 11:46:38 PM: \ttraining: 0.656250\n",
            "12/03 11:46:38 PM: \tvalidation: 0.691275\n",
            "12/03 11:46:39 PM: Saved files to RUN_DIR\n",
            "12/03 11:48:03 PM: Update 20: task cola, batch 10 (20): accuracy: 0.0000, acc: 0.7141, cola_loss: 0.6263 ||\n",
            "12/03 11:48:03 PM: ***** Pass 20 / Epoch 2 *****\n",
            "12/03 11:48:03 PM: cola: trained on 10 batches, 0.075 epochs\n",
            "12/03 11:48:03 PM: Validating...\n",
            "12/03 11:48:18 PM: Batch 2/17: accuracy: 0.0000, acc: 0.6953, cola_loss: 0.6672 ||\n",
            "12/03 11:48:35 PM: Batch 4/17: accuracy: 0.0000, acc: 0.6797, cola_loss: 0.6687 ||\n",
            "12/03 11:48:49 PM: Batch 6/17: accuracy: 0.0000, acc: 0.6901, cola_loss: 0.6669 ||\n",
            "12/03 11:49:05 PM: Batch 8/17: accuracy: 0.0000, acc: 0.6797, cola_loss: 0.6687 ||\n",
            "12/03 11:49:18 PM: Batch 10/17: accuracy: 0.0000, acc: 0.6953, cola_loss: 0.6663 ||\n",
            "12/03 11:49:33 PM: Batch 12/17: accuracy: 0.0000, acc: 0.6823, cola_loss: 0.6682 ||\n",
            "12/03 11:49:48 PM: Batch 14/17: accuracy: 0.0000, acc: 0.6808, cola_loss: 0.6681 ||\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 293, in <module>\n",
            "    sys.exit(main(sys.argv[1:]))\n",
            "  File \"main.py\", line 190, in main\n",
            "    args.load_model)\n",
            "  File \"/content/CS273A/src/trainer.py\", line 832, in train\n",
            "    self._validate(epoch, tasks, task_infos, metric_infos, iterator, g_scheduler)\n",
            "  File \"/content/CS273A/src/trainer.py\", line 896, in _validate\n",
            "    val_output_dict = self._forward(batch, task=task, for_training=False)\n",
            "  File \"/content/CS273A/src/trainer.py\", line 1004, in _forward\n",
            "    return self._model.forward(task, **tensor_batch)\n",
            "  File \"/content/CS273A/src/models.py\", line 220, in forward\n",
            "    sent_emb = self.sent_encoder(input1)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 357, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/CS273A/src/models.py\", line 420, in forward\n",
            "    elmo_embs = self._elmo(sent['elmo'])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 357, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/allennlp/modules/elmo.py\", line 125, in forward\n",
            "    bilm_output = self._elmo_lstm(reshaped_inputs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 357, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/allennlp/modules/elmo.py\", line 498, in forward\n",
            "    lstm_outputs = self._elmo_lstm(type_representation, mask)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 357, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/allennlp/modules/elmo_lstm.py\", line 122, in forward\n",
            "    self.sort_and_run_forward(self._lstm_forward, inputs, mask)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/allennlp/modules/encoder_base.py\", line 117, in sort_and_run_forward\n",
            "    module_output, final_states = module(packed_sequence_input, initial_states)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/allennlp/modules/elmo_lstm.py\", line 222, in _lstm_forward\n",
            "    backward_state)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 357, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/allennlp/modules/lstm_cell_with_projection.py\", line 183, in forward\n",
            "    projected_input = self.input_linearity(timestep_input)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 357, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\", line 55, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\", line 837, in linear\n",
            "    output = input.matmul(weight.t())\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/autograd/variable.py\", line 386, in matmul\n",
            "    return torch.matmul(self, other)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/functional.py\", line 174, in matmul\n",
            "    return torch.mm(tensor1, tensor2)\n",
            "KeyboardInterrupt\n",
            "\n",
            "If you suspect this is an IPython bug, please report it at:\n",
            "    https://github.com/ipython/ipython/issues\n",
            "or send an email to the mailing list at ipython-dev@python.org\n",
            "\n",
            "You can print a more detailed traceback right now with \"%tb\", or use \"%debug\"\n",
            "to interactively debug it.\n",
            "\n",
            "Extra-detailed tracebacks for bug-reporting purposes can be enabled via:\n",
            "    %config Application.verbose_crash=True\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-111fc09ca955>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sh run_stuff\\\\ \\\\(1\\\\).sh'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mShell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_send_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd)\u001b[0m\n\u001b[1;32m    434\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m   result = _run_command(\n\u001b[0;32m--> 436\u001b[0;31m       shell.var_expand(cmd, depth=2), clear_streamed_output=False)\n\u001b[0m\u001b[1;32m    437\u001b[0m   \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_INTERRUPTED_SIGNALS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    193\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_monitor_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_stdin_widget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_display_stdin_widget\u001b[0;34m(delay_millis)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m   \u001b[0mhide_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'cell_remove_stdin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m   \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocking_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mhide_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_header\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   \u001b[0;31m# unique.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "abUFkZ71-G9_",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "0b6772f7-1c78-44aa-f974-28d4b1f5bbcd"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b1994b2b-c9d8-454d-a99c-098cc448db42\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-b1994b2b-c9d8-454d-a99c-098cc448db42\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving run_stuff.sh to run_stuff (1).sh\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'run_stuff.sh': b'#!/bin/bash\\n# \\n#SBATCH -t 2-00:00\\n#SBATCH --gres=gpu:1080ti:1\\n#SBATCH --mail-type=end\\n#SBATCH --mail-user=aw3272@nyu.edu\\n\\n# SBATCH -t 4-00:00\\n# SBATCH --gres=gpu:p40:1\\n\\nSCRATCH_PREFIX=\\'../glue_data/\\'\\n#SCRATCH_PREFIX=\\'/beegfs/aw3272/\\'\\nPROJECT_NAME=\\'mtl-sent-rep\\'\\nEXP_NAME=\"debug\"\\nRUN_NAME=\"debug\"\\nGPUID=-1\\nSEED=19\\nno_tqdm=0\\n\\nSHOULD_TRAIN=1\\nLOAD_MODEL=0\\nLOAD_TASKS=1\\nLOAD_PREPROC=1\\nload_epoch=-1\\n\\ntrain_tasks=\\'cola\\'\\neval_tasks=\\'none\\'\\nCLASSIFIER=mlp\\nd_hid_cls=512\\nmax_seq_len=40\\nVOCAB_SIZE=30000\\n#WORD_EMBS_FILE=\"${SCRATCH_PREFIX}/raw_data/GloVe/glove.840B.300d.txt\"\\nWORD_EMBS_FILE=\"../glove/glove.6B/glove.6B.300d.txt\"\\n\\nd_word=300\\nd_hid=512\\nglove=0\\nELMO=1\\ndeep_elmo=1\\nelmo_no_glove=1\\nCOVE=0\\n\\nPAIR_ENC=\"simple\"\\nN_LAYERS_ENC=1\\nn_layers_highway=0\\n\\nOPTIMIZER=\"sgd\"\\nLR=.1\\nmin_lr=1e-5\\ndropout=.2\\nLR_DECAY=.5\\npatience=5\\ntask_patience=0\\ntrain_words=0\\nWEIGHT_DECAY=0.0\\nSCHED_THRESH=0.0\\nBATCH_SIZE=64\\nBPP_METHOD=\"percent_tr\"\\nBPP_BASE=10\\nVAL_INTERVAL=10\\nMAX_VALS=100\\nTASK_ORDERING=\"random\"\\nweighting_method=\"uniform\"\\nscaling_method=\\'none\\'\\n\\nwhile getopts \\'ikmn:r:S:s:tvh:l:L:o:T:E:O:b:H:p:edcgP:qB:V:M:D:C:X:GI:N:y:K:W:\\' flag; do\\n    case \"${flag}\" in\\n        P) SCRATCH_PREFIX=\"${OPTARG}\" ;;\\n        n) EXP_NAME=\"${OPTARG}\" ;;\\n        r) RUN_NAME=\"${OPTARG}\" ;;\\n        S) SEED=\"${OPTARG}\" ;;\\n        q) no_tqdm=1 ;;\\n        t) SHOULD_TRAIN=0 ;;\\n        k) LOAD_TASKS=0 ;;\\n        m) LOAD_MODEL=1 ;;\\n        i) LOAD_PREPROC=0 ;;\\n        M) BPP_METHOD=\"${OPTARG}\" ;; \\n        B) BPP_BASE=\"${OPTARG}\" ;;\\n        V) VAL_INTERVAL=\"${OPTARG}\" ;;\\n        X) MAX_VALS=\"${OPTARG}\" ;;\\n        T) train_tasks=\"${OPTARG}\" ;;\\n        #E) eval_tasks=\"${OPTARG}\" ;;\\n        O) TASK_ORDERING=\"${OPTARG}\" ;;\\n        H) n_layers_highway=\"${OPTARG}\" ;;\\n        l) LR=\"${OPTARG}\" ;;\\n        #s) min_lr=\"${OPTARG}\" ;;\\n        L) N_LAYERS_ENC=\"${OPTARG}\" ;;\\n        o) OPTIMIZER=\"${OPTARG}\" ;;\\n        h) d_hid=\"${OPTARG}\" ;;\\n        b) BATCH_SIZE=\"${OPTARG}\" ;;\\n        E) PAIR_ENC=\"${OPTARG}\" ;;\\n        G) glove=0 ;;\\n        e) ELMO=1 ;;\\n        d) deep_elmo=1 ;;\\n        g) elmo_no_glove=1 ;;\\n        c) COVE=1 ;;\\n        D) dropout=\"${OPTARG}\" ;;\\n        C) CLASSIFIER=\"${OPTARG}\" ;;\\n        I) GPUID=\"${OPTARG}\" ;;\\n        N) load_epoch=\"${OPTARG}\" ;;\\n        y) LR_DECAY=\"${OPTARG}\" ;;\\n        K) task_patience=\"${OPTARG}\" ;;\\n        p) patience=\"${OPTARG}\" ;;\\n        W) weighting_method=\"${OPTARG}\" ;;\\n        s) scaling_method=\"${OPTARG}\" ;;\\n    esac\\ndone\\n\\n#LOG_PATH=\"${SCRATCH_PREFIX}/ckpts/${PROJECT_NAME}/${EXP_NAME}/${RUN_NAME}/log.log\"\\nLOG_PATH=\"log.log\"\\n#EXP_DIR=\"${SCRATCH_PREFIX}/ckpts/${PROJECT_NAME}/${EXP_NAME}/\"\\nEXP_DIR=\"EXP_DIR\"\\n#RUN_DIR=\"${SCRATCH_PREFIX}/ckpts/${PROJECT_NAME}/${EXP_NAME}/${RUN_NAME}\"\\nRUN_DIR=\"RUN_DIR\"\\nmkdir -p ${EXP_DIR}\\nmkdir -p ${RUN_DIR}\\n\\nALLEN_CMD=\"python main.py --cuda ${GPUID} --random_seed ${SEED} --no_tqdm ${no_tqdm} --log_file ${LOG_PATH} --exp_dir ${EXP_DIR} --run_dir ${RUN_DIR} --train_tasks ${train_tasks} --eval_tasks ${eval_tasks} --classifier ${CLASSIFIER} --classifier_hid_dim ${d_hid_cls} --max_seq_len ${max_seq_len} --max_word_v_size ${VOCAB_SIZE} --word_embs_file ${WORD_EMBS_FILE} --train_words ${train_words} --glove ${glove} --elmo ${ELMO} --deep_elmo ${deep_elmo} --elmo_no_glove ${elmo_no_glove} --cove ${COVE} --d_word ${d_word} --d_hid ${d_hid} --n_layers_enc ${N_LAYERS_ENC} --pair_enc ${PAIR_ENC} --n_layers_highway ${n_layers_highway} --batch_size ${BATCH_SIZE} --bpp_method ${BPP_METHOD} --bpp_base ${BPP_BASE} --optimizer ${OPTIMIZER} --lr ${LR} --min_lr ${min_lr} --lr_decay_factor ${LR_DECAY} --task_patience ${task_patience} --patience ${patience} --weight_decay ${WEIGHT_DECAY} --dropout ${dropout} --val_interval ${VAL_INTERVAL} --max_vals ${MAX_VALS} --task_ordering ${TASK_ORDERING} --weighting_method ${weighting_method} --scaling_method ${scaling_method} --scheduler_threshold ${SCHED_THRESH} --load_model ${LOAD_MODEL} --load_tasks ${LOAD_TASKS} --load_preproc ${LOAD_PREPROC} --should_train ${SHOULD_TRAIN} --load_epoch ${load_epoch}\"\\neval ${ALLEN_CMD}\\n'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    }
  ]
}
